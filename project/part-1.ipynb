{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Neuroscience Crash Course (2019)\n",
    "** Arthur Leblois & Nicolas P. Rougier**, Institute of Neurodegenerative Diseases, Bordeaux, France.  \n",
    "Course material and program at https://github.com/rougier/CNCC-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"./pixar.jpg\">\n",
    "\n",
    "## Sort the birds!\n",
    "\n",
    "The goal of this project is to sort (automatically) audio files that correspond to the recording of adult or juvenile songbirds. If you listen to the audio files, you will hear that the sound is quite different between an adult (song) and a juvenile (babbling). This means we can probably process the audio files in order to decide if it corresponds to an adult or a juvenile and the goal is thus to write a function `songsort(\"./some-path/\")` that will automatically sort all the files present in `some-path` and label them accordingly.\n",
    "\n",
    "However, to do so, we'll need to manipulate a lot of different notions (such as resampling, filtering, enveloppe, auto-correlation, fit) and to check our implementation is correct. So let's start with a sample adult and juvenile audio file.\n",
    "\n",
    "**Data** is available [here](https://bfs.u-bordeaux.fr/telecharge.php?choix=files/7d41741dabba9bcad96ac304fd672d32/records.zip) until 13/07/2019. Once downloaded, you can unzip it in the project directory\n",
    "\n",
    "\n",
    "\n",
    "**Content**\n",
    "\n",
    "* [1. Configuration of the notebook](#1.-Configuration-of-the-notebook)\n",
    "* [2. Loading libraries](#2.-Loading-libraries)\n",
    "* [3. Loading data](#3.-Loading-data)\n",
    "* [4. Visualizing data](#4.-Visualizing-data)\n",
    "* [5. Denoising the signal](#5.-Denoising-the-signal)\n",
    "* [6. Smoothing the signal](#6.-Smoothing-the-signal)\n",
    "* [7. Resampling & Auto-correlation](#7.-Resampling-&-Auto-correlation)\n",
    "* [8. Wrap-up](#8.-Wrap-up)\n",
    "* [9. Batch processing](#9.-Batch-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuration of the notebook\n",
    "\n",
    "We need first to setup a few options in the notebook such as to have inline plots as well as a nicer output on OSX.  \n",
    "There is not much to understand here, these options are documented in the [Jupyer notebook documentation](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask jupyter to display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# OSX specific (for a nicer display on \"retina\" screen)\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In order to run the code in a specific code cell, you'll have to type `shift`+`return` on the selected cell. If you do that manually, you'll have to run each cell from top to bottom (order is important). If you want to run all the cell, you can also click the run button at the top of the notebook. To edit a cell (code or text), double-click in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "### 2. Loading libraries\n",
    "Next step is to load all the Python libraries that will be needed for processing & displaying our data. Namely:\n",
    "* [NumPy](https://www.numpy.org/) which is the fundamental package for scientific computing with Python.\n",
    "* [Matplotlib](https://matplotlib.org/) which is a plotting library that produces publication quality figures. \n",
    "* [SciPy](https://www.scipy.org/) which is a Python-based ecosystem of open-source software for mathematics, science, and engineering.\n",
    "* [IPython](https://ipython.org/) that provides a rich architecture for interactive computing\n",
    "\n",
    "Note that during this course, we'll only use a small part of IPython (to play sound)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical package\n",
    "import numpy as np\n",
    "\n",
    "# Signal processing\n",
    "import scipy.signal\n",
    "\n",
    "# Package to display figures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Package to read wav files\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Package to display widgets inside the notebook\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### 3. Loading data\n",
    "\n",
    "The first thing to do is to load our data from a local file that must be present in your `data` directory. To do that, we'll write a `get_local_data` function that reads a `wav` filename (`wav` file are sound files encoded in the [Waveform audio file format](https://fr.wikipedia.org/wiki/Waveform_Audio_File_Format)) using a dedicated function of scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename = None):\n",
    "    rate, signal = wavfile.read(filename)\n",
    "    return rate, signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load some data and check for their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./records/record-001.wav\"\n",
    "\n",
    "rate, S = get_data(filename)\n",
    "print(\"Frequency: {:.1f}kHz\".format(rate/1000))\n",
    "print(\"Length: {}\".format(len(S)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "The file has been read and we know that the frequency is 44.1 kHz and the number of data points is 530833.  \n",
    "Try to compute the duration of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to the exercise\n",
    "duration = len(S)/rate\n",
    "print(\"Frequency: {:.1f}kHz\".format(rate/1000))\n",
    "print(\"Duration: {:.2f} second(s)\".format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Visualizing data\n",
    "\n",
    "We can now display our data using the `plot` function from matplotlib. To do that, we need to have the X and Y coordinates of points. The Y data is given by the `signal` but we need to generate the corresponding X data. Knowing the duration and the number of Y data, we can write X using the numpy [linspace(start,stop,num)](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html) function as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.linspace(0, duration, len(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to create a new figure and plot our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(T, S);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see only a subpart of the signal, you can limit explicitely the x range using the [xlim(xmin,xmax)](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlim.html) function as shown below where we modified the y range as well using the [ylim(ymin,ymax)](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylim.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(T, S);\n",
    "plt.xlim(1.95,2.0);\n",
    "plt.ylim(-5000,5000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, and knowing our data is an audio file, we can benefit from a better visualization using the [specgram](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.specgram.html) function of matplotlib that is dedicated to the visualization of spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,3))\n",
    "plt.specgram(S, Fs=rate, cmap=\"magma\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last, but not least, using the IPython library, we can display a widget in order to play the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display a widget to play the sound\n",
    "display(Audio(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Denoising the signal\n",
    "\n",
    "Before going any further in our processing, we need to remove noise originating from recording default and ambient noise. We'll use a [high-pass filter (HPF)](https://en.wikipedia.org/wiki/High-pass_filter) that is  *an electronic filter that passes signals with a frequency higher than a certain cutoff frequency and attenuates signals with frequencies lower than the cutoff frequency* (Wikipedia). To do that, we first need to build a filter among [those available](https://docs.scipy.org/doc/scipy/reference/signal.html) and we apply the filter to our signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, a = scipy.signal.butter(2, 500, \"high\", output='ba', fs=rate)\n",
    "S_ = scipy.signal.filtfilt(b, a, S)\n",
    "D = S - S_\n",
    "S = S_\n",
    "\n",
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(T, S_);\n",
    "plt.plot(T, D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy version\n",
    "display(Audio(S, rate=rate));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoised signal\n",
    "display(Audio(S_, rate=rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Smoothing the signal\n",
    "\n",
    "We want to smooth the signal by averaging each value with neighboring values, using a Gaussian window. To do that, we first need to define the neighboring range (in seconds). Then we define a gaussian signal over this range and centered in the middle and finally we compute the smooth signal (enveloppe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration of the time window over which to smooth the signal\n",
    "dt = 0.025\n",
    "trange = int(dt*rate)\n",
    "# Standard deviation of the gaussian\n",
    "sigma = trange/4\n",
    "# Actual temporal window over which to compute the Gaussian\n",
    "window = np.arange(-trange//2,trange//2)\n",
    "# Gaussian function over window and standard deviation sigma\n",
    "gaussian = np.exp(-(window/sigma)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize our smoothing window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the Gaussian \n",
    "plt.plot(window/rate, gaussian);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us compte the envelope using the  convolution product that is mathematically defined as:\n",
    "$(f * g)(t) \\triangleq\\ \\int_{-\\infty}^\\infty f(t-\\tau) g(\\tau)\\, d\\tau$\n",
    "\n",
    "The illustration below (from the [Wikipedia page on convolution](https://en.wikipedia.org/wiki/Convolution)) shows how it is computed:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/6/6a/Convolution_of_box_signal_with_itself2.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the signal using the numpy convolution function\n",
    "E = np.convolve(np.abs(S), gaussian, mode='same') / gaussian.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did things properly, the signal and it enveloppe variations should be aligned.  \n",
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the raw signal and the spectrogram\n",
    "T = np.linspace(0, duration, len(S))\n",
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(T, abs(S), alpha=0.5)\n",
    "plt.plot(T, E, color=\"black\")\n",
    "plt.xlim(1,3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Resampling & Auto-correlation\n",
    "\n",
    "We can now compute the auto-correlation of the signal, that is, the correlation of the signal by itself. Howewer, since the signal is quite large, we'll first extract only a few points linearly spread over the signal and then compute the auto-correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = E[::100]\n",
    "C = np.correlate(E, E, mode='same') / (E**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An we can now visualize the result in the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T = .5*np.linspace(-len(S)/rate, +len(S)/rate , len(C))\n",
    "plt.plot(T, C);\n",
    "plt.xlim(-0.5,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visually see there is a peak a the center. Let's see what happens for a juvenile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Wrap-up\n",
    "\n",
    "It's now time to write a function that, given a wav file, compute the auto-corraltion. To do this, we just need to wrap-up what we've written so far and choose the relevant arguments to give when we call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(data, dt=0.025):\n",
    "    \"\"\"\n",
    "    Compute the auto-correlation of an audio signal using a Gaussian\n",
    "    smoothing window (with duration dt)\n",
    "    \n",
    "    data: (rate, signal)\n",
    "        data is an audio signal made of 2 variables. First one (rate)\n",
    "        is the frequency of the signal and second one (signal) is the\n",
    "        actual signal.\n",
    "    \n",
    "    dt: float\n",
    "        Duration of the time window (Gaussian) to smooth the signal. \n",
    "        Default value is 250 milliseconds.\n",
    "    \"\"\"\n",
    "    \n",
    "    rate, S = data\n",
    "    duration = len(S)/rate\n",
    "    \n",
    "    b, a =  scipy.signal.butter(2, 200, \"high\", output='ba', fs=rate)\n",
    "    S = scipy.signal.filtfilt(b, a, S)\n",
    "    \n",
    "    window = np.arange(-dt*rate//2,dt*rate//2)\n",
    "    gaussian = np.exp(-(4*window/(dt*rate))**2)\n",
    "    R = (np.convolve(abs(S), gaussian, mode='same') / gaussian.sum())[::100]\n",
    "    C = np.correlate(R, R, mode='same') / (R**2).sum()\n",
    "    T = np.linspace(-duration/2, +duration/2 , len(C))\n",
    "    return T, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Batch processing\n",
    "\n",
    "So far, we've working with a unique file whose name was known to us. We would like now to process all the wav files in the data directory. This means we need to first find them and then process them. To do that, we'll use the [glob](https://docs.python.org/3/library/glob.html) library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(\"./records/*.wav\")[:4]\n",
    "\n",
    "ax = None\n",
    "plt.figure(figsize=(16,4))\n",
    "for index, filename in enumerate(files):\n",
    "    T, C = autocorr(get_data(filename))\n",
    "    ax = plt.subplot(1, 4, 1+index, aspect=1, sharey=ax);\n",
    "    ax.plot(T, C);\n",
    "    ax.set_xlim(-0.5,0.5);\n",
    "    ax.set_title(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
